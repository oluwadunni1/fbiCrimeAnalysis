# Load necessary libraries
library(tidyverse)
library(stringdist)  # For fuzzy matching
library(maps)        # For reference county data

# Load the processed dataset
agencies <- readRDS("data/processed/agencies_processed.rds")

# Step 1: Load the reference dataset of US counties correctly
data(county.fips)  # This loads county data in a different format
us_counties <- county.fips %>%
  separate(polyname, c("state", "county"), sep = ",") %>%
  mutate(
    state = str_to_title(state),
    county = str_to_title(county)
  ) %>%
  select(state, county) %>%
  distinct()

# Step 2: Create an improved standardize function that handles common variations
standardize_name <- function(name) {
  name %>%
    str_to_title() %>%                                 # Convert to Title Case
    str_replace_all("[[:punct:]]", "") %>%            # Remove punctuation
    str_replace_all(" County$| Co$| Parish$| Borough$", "") %>%  # Remove suffixes
    str_replace_all("^Saint ", "St ") %>%             # Common abbreviations
    str_replace_all("^Fort ", "Ft ") %>%
    str_trim()                                         # Trim whitespace
}

# Step 3: Standardize county names in both datasets
agencies <- agencies %>%
  mutate(
    original_county = county,  # Preserve original values
    county = standardize_name(county)
  )

us_counties <- us_counties %>%
  mutate(county = standardize_name(county))

# Step 4: Function to perform matching with proper error handling and thresholds
match_county <- function(county_name, state_name, county_data, threshold = 0.2) {
  tryCatch({
    # Filter to just counties in this state
    state_counties <- county_data %>% 
      filter(state == state_name)
    
    if(nrow(state_counties) == 0) {
      return(list(corrected = NA_character_, 
                  distance = NA_real_, 
                  valid = FALSE))
    }
    
    # Calculate distances to all counties in this state
    distances <- stringdist(county_name, state_counties$county, method = "jw")
    
    # Find the best match
    best_idx <- which.min(distances)
    best_distance <- distances[best_idx]
    best_match <- state_counties$county[best_idx]
    
    # Apply threshold
    if(best_distance <= threshold) {
      return(list(corrected = best_match, 
                  distance = best_distance, 
                  valid = TRUE))
    } else {
      return(list(corrected = best_match, 
                  distance = best_distance, 
                  valid = FALSE))
    }
  }, error = function(e) {
    warning(paste("Error processing county:", county_name, "in state:", state_name, "-", e$message))
    return(list(corrected = NA_character_, 
                distance = NA_real_, 
                valid = FALSE))
  })
}

# Step 5: Run a test on a small sample to verify approach
set.seed(123)  # For reproducible sampling
sample_size <- min(100, nrow(agencies))
sample_agencies <- agencies %>% sample_n(sample_size)

# Apply matching to sample
sample_results <- sample_agencies %>%
  rowwise() %>%
  mutate(
    match_result = list(match_county(county, state, us_counties, threshold = 0.2)),
    corrected_county = match_result$corrected,
    match_distance = match_result$distance,
    match_valid = match_result$valid,
    match_similarity = 1 - match_distance,
    needs_review = !match_valid | match_similarity < 0.8
  ) %>%
  select(-match_result) %>%
  ungroup()

# Check sample results
cat("Sample results summary:\n")
cat("Total sample size:", nrow(sample_results), "\n")
cat("Valid matches:", sum(sample_results$match_valid, na.rm = TRUE), "\n")
cat("Matches needing review:", sum(sample_results$needs_review, na.rm = TRUE), "\n")

# Step 6: Apply to full dataset if sample results look good
cat("\nApplying to full dataset...\n")

agencies_corrected <- agencies %>%
  rowwise() %>%
  mutate(
    match_result = list(match_county(county, state, us_counties, threshold = 0.2)),
    corrected_county = match_result$corrected,
    match_distance = match_result$distance,
    match_valid = match_result$valid,
    match_similarity = 1 - match_distance,
    needs_review = !match_valid | match_similarity < 0.8
  ) %>%
  select(-match_result) %>%
  ungroup()

# Step 7: Verify the results
cat("\nFull dataset results summary:\n")
cat("Total entries:", nrow(agencies_corrected), "\n")
cat("Valid matches:", sum(agencies_corrected$match_valid, na.rm = TRUE), "\n")
cat("Entries needing review:", sum(agencies_corrected$needs_review, na.rm = TRUE), "\n")

# Export entries that need review to a CSV
agencies_corrected %>%
  filter(needs_review) %>%
  select(original_county, county, state, corrected_county, match_similarity, match_valid) %>%
  write_csv("data/processed/counties_to_review.csv")

cat("\nEntries needing manual review exported to: data/processed/counties_to_review.csv\n")

# Step 8: Save the corrected dataset
saveRDS(agencies_corrected, "data/processed/agencies_corrected_counties.rds")
cat("\nCorrected dataset saved to: data/processed/agencies_corrected_counties.rds\n")

# Step 9: Show sample corrections
cat("\nSample corrections (first 10 rows that changed):\n")
agencies_corrected %>%
  filter(original_county != corrected_county, match_valid) %>%
  select(original_county, corrected_county, state, match_similarity) %>%
  head(10) %>%
  print()